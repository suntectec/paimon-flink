env {
  parallelism = 1
  job.mode = "STREAMING"
  checkpoint.interval = 10000
}

source {
  Kafka {
    bootstrap.servers = "192.168.138.15:9092"
    tables_configs = [
      {
        topic = "order_json_format"
        pattern = "true"
        consumer.group = "poc-group"
        start_mode = earliest
        schema = {
          fields {
            id = "int"
            order_id = "string"
            supplier_id = "int"
            item_id = "int"
            status = "string"
            qty = "int"
            net_price = "int"
            issued_at = "string"
            completed_at = "string"
            spec = "string"
            created_at = "string"
            updated_at = "string"
            }
        },
        format = json
      }
    ]
  }
}

sink {
  Paimon {
    warehouse = "s3a://tmp/kafka/seatunnel/"
    database="${database_name}_test"
    table="${table_name}_test"
    paimon.hadoop.conf = {
      fs.s3a.access-key=${MINIO_ROOT_USER}
      fs.s3a.secret-key=${MINIO_ROOT_PASSWORD}
      fs.s3a.endpoint="http://"${LOCALHOST_IP}":9000"
      fs.s3a.path.style.access=true
      fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    }
    paimon.table.write-props = {
      bucket = -1
      dynamic-bucket.target-row-num = 50000
    }
    paimon.table.primary-keys = "id"
  }
}